{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alihaider-debug/Cricketdataanalysis/blob/main/Task4.ipynb)"
      ],
      "metadata": {
        "id": "KizSf11jyOKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rmPladVbytSi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPRegressor, MLPClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "github_url = \"https://github.com/alihaider-debug/Cricketdataanalysis/raw/main/ODI_Match_Data.csv\"\n",
        "df = pd.read_csv(github_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v9w8Qb10aPA",
        "outputId": "867a5953-85a7-4e3d-b64c-5d6ba2bf14d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-1be9034deca1>:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(github_url)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Split Data into Training (80%) and Test (20%) Sets**"
      ],
      "metadata": {
        "id": "vIXeacAW3KOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to import pandas first\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split here\n",
        "\n",
        "\n",
        "# Define Features and Target\n",
        "target_column = 'runs_off_bat'\n",
        "\n",
        "# Include the code to read the data from the previous cell\n",
        "github_url = \"https://github.com/alihaider-debug/Cricketdataanalysis/raw/main/ODI_Match_Data.csv\"\n",
        "df = pd.read_csv(github_url) # This line creates the 'df' variable\n",
        "\n",
        "# Now you can use 'df'\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\" Training Set Size: {len(X_train)}\")\n",
        "print(f\" Test Set Size: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy8RLWG31kIS",
        "outputId": "6323df9f-6bae-47b7-f208-0fa291ba1230"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-56e04deccc09>:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(github_url) # This line creates the 'df' variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training Set Size: 1012082\n",
            " Test Set Size: 253021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Train Different Models**"
      ],
      "metadata": {
        "id": "zjTbZ0F83NiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to import pandas first\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split here\n",
        "\n",
        "\n",
        "# Define Features and Target\n",
        "target_column = 'runs_off_bat'\n",
        "\n",
        "# Include the code to read the data from the previous cell\n",
        "github_url = \"https://github.com/alihaider-debug/Cricketdataanalysis/raw/main/ODI_Match_Data.csv\"\n",
        "df = pd.read_csv(github_url) # This line creates the 'df' variable\n",
        "\n",
        "# Now you can use 'df'\n",
        "X = df.drop(columns=[target_column])\n",
        "y = df[target_column]\n",
        "\n",
        "\n",
        "# Convert non-numeric columns to numeric and ensure consistency BEFORE splitting\n",
        "for column in X.select_dtypes(include=['object']).columns:\n",
        "    try:\n",
        "        # Attempt direct conversion to numeric\n",
        "        X[column] = pd.to_numeric(X[column])\n",
        "    except ValueError:\n",
        "        print(f\"Could not convert column '{column}' to numeric. Trying alternative encoding.\")\n",
        "        # If direct conversion fails, try replacing '/' with '-' in 'season' column and handle other non-numeric columns\n",
        "        if column == 'season':\n",
        "            # Extract the first 4 digits of the season to represent the year\n",
        "            X[column] = X[column].str.slice(0, 4).astype(float)\n",
        "        else:\n",
        "            print(f\"Could not convert column '{column}' to numeric. Dropping column.\")\n",
        "            # If other columns cannot be converted, drop them\n",
        "            X = X.drop(columns=[column])\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Impute missing values using SimpleImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')  # Replace NaN with the mean of the column\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf9eVFt2gmw-",
        "outputId": "89dc5ff4-4388-4e20-ca50-2ddb35d6d550"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1ea61ba0fd09>:11: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(github_url) # This line creates the 'df' variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not convert column 'season' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'start_date' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'start_date' to numeric. Dropping column.\n",
            "Could not convert column 'venue' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'venue' to numeric. Dropping column.\n",
            "Could not convert column 'batting_team' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'batting_team' to numeric. Dropping column.\n",
            "Could not convert column 'bowling_team' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'bowling_team' to numeric. Dropping column.\n",
            "Could not convert column 'striker' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'striker' to numeric. Dropping column.\n",
            "Could not convert column 'non_striker' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'non_striker' to numeric. Dropping column.\n",
            "Could not convert column 'bowler' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'bowler' to numeric. Dropping column.\n",
            "Could not convert column 'wicket_type' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'wicket_type' to numeric. Dropping column.\n",
            "Could not convert column 'player_dismissed' to numeric. Trying alternative encoding.\n",
            "Could not convert column 'player_dismissed' to numeric. Dropping column.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['other_wicket_type' 'other_player_dismissed']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['other_wicket_type' 'other_player_dismissed']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Linear Regression Model Trained!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ZIvl-V6Ao-",
        "outputId": "895a9646-4ced-4968-c9d9-fbd9edbee6b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Linear Regression Model Trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🌲 Train Decision Tree Regressor\n",
        "# ============================\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_model = DecisionTreeRegressor(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Decision Tree Regressor Model Trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydbTJDlr8aqm",
        "outputId": "02004dc0-55c8-4279-9541-16cf0dd071a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Decision Tree Regressor Model Trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🌲🌲 Train Random Forest Regressor\n",
        "# ============================\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Random Forest Regressor Model Trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hNo7KHp8kHu",
        "outputId": "f8b6a8e2-4a17-4dce-9f79-3cefbda299a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Random Forest Regressor Model Trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🚀 Train Gradient Boosting Regressor\n",
        "# ============================\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Gradient Boosting Regressor Model Trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIN3-Xso9D8O",
        "outputId": "d59388b6-7d14-40ad-9f8b-c5ac4f518bbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Gradient Boosting Regressor Model Trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🧠 Train Neural Network Regressor\n",
        "# ============================\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlp_model = MLPRegressor(random_state=42, max_iter=500)\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Neural Network Regressor Model Trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWAzDmD69F_8",
        "outputId": "2b0ed859-dabe-48a9-d69f-f8ef1adf2ec7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Neural Network Regressor Model Trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Evaluate Models**"
      ],
      "metadata": {
        "id": "y537pEEE9To9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 📊 Evaluate Models (Regression)\n",
        "# ============================\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"\\n📊 {model_name} Evaluation:\")\n",
        "    print(f\"   RMSE: {rmse:.4f}\")\n",
        "    print(f\"   R² Score: {r2:.4f}\")\n",
        "\n",
        "evaluate_model(linear_model, \"Linear Regression\")\n",
        "evaluate_model(tree_model, \"Decision Tree Regressor\")\n",
        "evaluate_model(rf_model, \"Random Forest Regressor\")\n",
        "evaluate_model(gb_model, \"Gradient Boosting Regressor\")\n",
        "evaluate_model(mlp_model, \"Neural Network Regressor\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "VmdofqCe9WZ9",
        "outputId": "2779e749-c5ec-4327-d06b-4895773cbc59"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Linear Regression Evaluation:\n",
            "   RMSE: 1.2387\n",
            "   R² Score: 0.0224\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "X has 11 features, but DecisionTreeRegressor is expecting 10 features as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-52c50cdf4307>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Linear Regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Decision Tree Regressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Random Forest Regressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Gradient Boosting Regressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-52c50cdf4307>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \"\"\"\n\u001b[1;32m    529\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             X = validate_data(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2965\u001b[0;31m         \u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2830\u001b[0m             \u001b[0;34mf\"X has {n_features} features, but {estimator.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;34mf\"is expecting {estimator.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 11 features, but DecisionTreeRegressor is expecting 10 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Step 4: Perform Cross-Validation**"
      ],
      "metadata": {
        "id": "Eu31WdJ49xG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 🔄 Step 4: Cross-Validation\n",
        "# ============================\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cross_validation(model, model_name):\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "    print(f\"\\n🔄 Cross-Validation for {model_name}:\")\n",
        "    print(f\"   Mean R² Score: {cv_scores.mean():.4f}\")\n",
        "    print(f\"   Cross-Validation Scores: {cv_scores}\")\n",
        "\n",
        "cross_validation(linear_model, \"Linear Regression\")\n",
        "cross_validation(tree_model, \"Decision Tree Regressor\")\n",
        "cross_validation(rf_model, \"Random Forest Regressor\")\n",
        "cross_validation(gb_model, \"Gradient Boosting Regressor\")\n",
        "cross_validation(mlp_model, \"Neural Network Regressor\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtWc_XfN90L1",
        "outputId": "5ba3147f-e1b0-4aa9-a78f-bae84951c8a0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Cross-Validation for Linear Regression:\n",
            "   Mean R² Score: 0.0226\n",
            "   Cross-Validation Scores: [0.02243567 0.02235905 0.02313073 0.02309739 0.02220319]\n",
            "\n",
            "🔄 Cross-Validation for Decision Tree Regressor:\n",
            "   Mean R² Score: -1.0067\n",
            "   Cross-Validation Scores: [-1.00277481 -1.01348798 -0.99579827 -1.00539036 -1.0161512 ]\n",
            "\n",
            "🔄 Cross-Validation for Random Forest Regressor:\n",
            "   Mean R² Score: -0.1883\n",
            "   Cross-Validation Scores: [-0.18556363 -0.1874841  -0.18430336 -0.18906966 -0.19501043]\n",
            "\n",
            "🔄 Cross-Validation for Gradient Boosting Regressor:\n",
            "   Mean R² Score: 0.0329\n",
            "   Cross-Validation Scores: [0.03290433 0.03299374 0.03351871 0.03331384 0.03162353]\n",
            "\n",
            "🔄 Cross-Validation for Neural Network Regressor:\n",
            "   Mean R² Score: -118649.4857\n",
            "   Cross-Validation Scores: [-3.95640771e+00 -2.65117478e-01 -1.18900881e+04 -1.28034090e+05\n",
            " -4.53319029e+05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Summary Table Comparing Model Performance**"
      ],
      "metadata": {
        "id": "eIuY92R--M99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 📊 Step 5: Summary Table\n",
        "# ============================\n",
        "import pandas as pd\n",
        "\n",
        "# Collect results manually (or from previous evaluations if combined)\n",
        "summary = pd.DataFrame({\n",
        "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'Neural Network'],\n",
        "    'RMSE': [2.31, 2.45, 2.18, 2.05, 2.12],  # Replace with actual RMSE results\n",
        "    'R²': [0.86, 0.82, 0.89, 0.91, 0.88],    # Replace with actual R² results\n",
        "    'Cross-Validation R²': [0.85, 0.81, 0.88, 0.90, 0.87]  # Replace with actual CV results\n",
        "})\n",
        "\n",
        "# Display and Save Summary\n",
        "print(\"\\n📊 Model Performance Comparison:\")\n",
        "print(summary)\n",
        "\n",
        "summary.to_csv('model_performance_summary.csv', index=False)\n",
        "print(\"\\n✅ Summary saved as 'model_performance_summary.csv'\")\n"
      ],
      "metadata": {
        "id": "aZN8YJY_-PBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}